game: othello

GameType.chance_mode = ChanceMode.DETERMINISTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.PERFECT_INFORMATION
GameType.long_name = "Othello"
GameType.max_num_players = 2
GameType.min_num_players = 2
GameType.parameter_specification = []
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = False
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "othello"
GameType.utility = Utility.ZERO_SUM

NumDistinctActions() = 65
PolicyTensorShape() = [65]
MaxChanceOutcomes() = 0
GetParameters() = {}
NumPlayers() = 2
MinUtility() = -1.0
MaxUtility() = 1.0
UtilitySum() = 0.0
ObservationTensorShape() = [3, 8, 8]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 192
MaxGameLength() = 64
ToString() = "othello()"

# State 0
# Black (x) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - - - - - - 3
# 4 - - - o x - - - 4
# 5 - - - x o - - - 5
# 6 - - - - - - - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = ""
InformationStateString(1) = ""
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - - o x - - - 4\n5 - - - x o - - - 5\n6 - - - - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - - o x - - - 4\n5 - - - x o - - - 5\n6 - - - - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [19, 26, 37, 44]
StringLegalActions() = ["d3", "c4", "f5", "e6"]

# Apply action "e6"
action: 44

# State 1
# White (o) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - - - - - - 3
# 4 - - - o x - - - 4
# 5 - - - x x - - - 5
# 6 - - - - x - - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44]
HistoryString() = "44"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44"
InformationStateString(1) = "44"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - - o x - - - 4\n5 - - - x x - - - 5\n6 - - - - x - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - - o x - - - 4\n5 - - - x x - - - 5\n6 - - - - x - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◉◉◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [29, 43, 45]
StringLegalActions() = ["f4", "d6", "f6"]

# Apply action "d6"
action: 43

# State 2
# Black (x) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - - - - - - 3
# 4 - - - o x - - - 4
# 5 - - - o x - - - 5
# 6 - - - o x - - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43]
HistoryString() = "44 43"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43"
InformationStateString(1) = "44 43"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - - o x - - - 4\n5 - - - o x - - - 5\n6 - - - o x - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - - o x - - - 4\n5 - - - o x - - - 5\n6 - - - o x - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [18, 26, 34, 42, 50]
StringLegalActions() = ["c3", "c4", "c5", "c6", "c7"]

# Apply action "c4"
action: 26

# State 3
# White (o) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - - - - - - 3
# 4 - - x x x - - - 4
# 5 - - - x x - - - 5
# 6 - - - o x - - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26]
HistoryString() = "44 43 26"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26"
InformationStateString(1) = "44 43 26"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - x x x - - - 4\n5 - - - x x - - - 5\n6 - - - o x - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - x x x - - - 4\n5 - - - x x - - - 5\n6 - - - o x - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [19, 29, 45]
StringLegalActions() = ["d3", "f4", "f6"]

# Apply action "f4"
action: 29

# State 4
# Black (x) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - - - - - - 3
# 4 - - x x x o - - 4
# 5 - - - x o - - - 5
# 6 - - - o x - - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29]
HistoryString() = "44 43 26 29"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29"
InformationStateString(1) = "44 43 26 29"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - x x x o - - 4\n5 - - - x o - - - 5\n6 - - - o x - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - x x x o - - 4\n5 - - - x o - - - 5\n6 - - - o x - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◉◉◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [30, 37, 42, 45, 51]
StringLegalActions() = ["g4", "f5", "c6", "f6", "d7"]

# Apply action "f6"
action: 45

# State 5
# White (o) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - - - - - - 3
# 4 - - x x x o - - 4
# 5 - - - x x - - - 5
# 6 - - - o x x - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45]
HistoryString() = "44 43 26 29 45"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45"
InformationStateString(1) = "44 43 26 29 45"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - x x x o - - 4\n5 - - - x x - - - 5\n6 - - - o x x - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - x x x o - - 4\n5 - - - x x - - - 5\n6 - - - o x x - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◉◉◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [19, 25, 46]
StringLegalActions() = ["d3", "b4", "g6"]

# Apply action "b4"
action: 25

# State 6
# Black (x) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - - - - - - 3
# 4 - o o o o o - - 4
# 5 - - - x x - - - 5
# 6 - - - o x x - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25]
HistoryString() = "44 43 26 29 45 25"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25"
InformationStateString(1) = "44 43 26 29 45 25"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - o o o o o - - 4\n5 - - - x x - - - 5\n6 - - - o x x - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - o o o o o - - 4\n5 - - - x x - - - 5\n6 - - - o x x - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [17, 18, 19, 20, 21, 22, 42, 50, 51]
StringLegalActions() = ["b3", "c3", "d3", "e3", "f3", "g3", "c6", "c7", "d7"]

# Apply action "b3"
action: 17

# State 7
# White (o) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - x - - - - - - 3
# 4 - o x o o o - - 4
# 5 - - - x x - - - 5
# 6 - - - o x x - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17]
HistoryString() = "44 43 26 29 45 25 17"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17"
InformationStateString(1) = "44 43 26 29 45 25 17"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - x - - - - - - 3\n4 - o x o o o - - 4\n5 - - - x x - - - 5\n6 - - - o x x - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - x - - - - - - 3\n4 - o x o o o - - 4\n5 - - - x x - - - 5\n6 - - - o x x - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [9, 42, 46, 52, 54]
StringLegalActions() = ["b2", "c6", "g6", "e7", "g7"]

# Apply action "e7"
action: 52

# State 8
# Black (x) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - x - - - - - - 3
# 4 - o x o o o - - 4
# 5 - - - x o - - - 5
# 6 - - - o o x - - 6
# 7 - - - - o - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52]
HistoryString() = "44 43 26 29 45 25 17 52"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52"
InformationStateString(1) = "44 43 26 29 45 25 17 52"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - x - - - - - - 3\n4 - o x o o o - - 4\n5 - - - x o - - - 5\n6 - - - o o x - - 6\n7 - - - - o - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - x - - - - - - 3\n4 - o x o o o - - 4\n5 - - - x o - - - 5\n6 - - - o o x - - 6\n7 - - - - o - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◉◉◯◯◯
◉◉◉◉◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [18, 19, 21, 24, 30, 33, 37, 42, 51, 53, 59]
StringLegalActions() = ["c3", "d3", "f3", "a4", "g4", "b5", "f5", "c6", "d7", "f7", "d8"]

# Apply action "f3"
action: 21

# State 9
# White (o) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - x - - - x - - 3
# 4 - o x o x o - - 4
# 5 - - - x o - - - 5
# 6 - - - o o x - - 6
# 7 - - - - o - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21]
HistoryString() = "44 43 26 29 45 25 17 52 21"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - x - - - x - - 3\n4 - o x o x o - - 4\n5 - - - x o - - - 5\n6 - - - o o x - - 6\n7 - - - - o - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - x - - - x - - 3\n4 - o x o x o - - 4\n5 - - - x o - - - 5\n6 - - - o o x - - 6\n7 - - - - o - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◉◯◯◯  ◯◉◯◉◯◉◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◉◉◯◯◯
◉◉◉◉◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◯◉◯◯  ◯◯◉◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [8, 9, 13, 20, 34, 38, 46, 54]
StringLegalActions() = ["a2", "b2", "f2", "e3", "c5", "g5", "g6", "g7"]

# Apply action "f2"
action: 13

# State 10
# Black (x) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - o - - 2
# 3 - x - - - o - - 3
# 4 - o x o x o - - 4
# 5 - - - x o - - - 5
# 6 - - - o o x - - 6
# 7 - - - - o - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13]
HistoryString() = "44 43 26 29 45 25 17 52 21 13"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - o - - 2\n3 - x - - - o - - 3\n4 - o x o x o - - 4\n5 - - - x o - - - 5\n6 - - - o o x - - 6\n7 - - - - o - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - o - - 2\n3 - x - - - o - - 3\n4 - o x o x o - - 4\n5 - - - x o - - - 5\n6 - - - o o x - - 6\n7 - - - - o - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◉◉◉◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◉◯◯◯  ◯◉◯◉◯◉◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◉◉◯◯◯
◉◉◉◉◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◯◉◯◯  ◯◯◉◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [14, 18, 19, 24, 30, 33, 37, 42, 51, 53, 59, 60]
StringLegalActions() = ["g2", "c3", "d3", "a4", "g4", "b5", "f5", "c6", "d7", "f7", "d8", "e8"]

# Apply action "f5"
action: 37

# State 11
# White (o) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - o - - 2
# 3 - x - - - o - - 3
# 4 - o x o x o - - 4
# 5 - - - x x x - - 5
# 6 - - - o o x - - 6
# 7 - - - - o - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - o - - 2\n3 - x - - - o - - 3\n4 - o x o x o - - 4\n5 - - - x x x - - 5\n6 - - - o o x - - 6\n7 - - - - o - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - o - - 2\n3 - x - - - o - - 3\n4 - o x o x o - - 4\n5 - - - x x x - - 5\n6 - - - o o x - - 6\n7 - - - - o - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◉◉◉◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◉◯◯◯  ◯◉◯◉◯◉◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◉◉◯◯◯
◉◉◉◉◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◯◉◯◯  ◯◯◉◯◉◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [8, 9, 20, 30, 38, 42, 46, 53, 54]
StringLegalActions() = ["a2", "b2", "e3", "g4", "g5", "c6", "g6", "f7", "g7"]

# Apply action "c6"
action: 42

# State 12
# Black (x) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - o - - 2
# 3 - x - - - o - - 3
# 4 - o x o o o - - 4
# 5 - - - o x x - - 5
# 6 - - o o o x - - 6
# 7 - - - - o - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - o - - 2\n3 - x - - - o - - 3\n4 - o x o o o - - 4\n5 - - - o x x - - 5\n6 - - o o o x - - 6\n7 - - - - o - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - o - - 2\n3 - x - - - o - - 3\n4 - o x o o o - - 4\n5 - - - o x x - - 5\n6 - - o o o x - - 6\n7 - - - - o - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◉◉◉◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◉◉◉◯◯◯
◉◉◉◉◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [5, 18, 19, 20, 22, 24, 30, 33, 34, 41, 50, 51, 53, 59, 60]
StringLegalActions() = ["f1", "c3", "d3", "e3", "g3", "a4", "g4", "b5", "c5", "b6", "c7", "d7", "f7", "d8", "e8"]

# Apply action "b6"
action: 41

# State 13
# White (o) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - o - - 2
# 3 - x - - - o - - 3
# 4 - o x o o o - - 4
# 5 - - - o x x - - 5
# 6 - x x x x x - - 6
# 7 - - - - o - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - o - - 2\n3 - x - - - o - - 3\n4 - o x o o o - - 4\n5 - - - o x x - - 5\n6 - x x x x x - - 6\n7 - - - - o - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - o - - 2\n3 - x - - - o - - 3\n4 - o x o o o - - 4\n5 - - - o x x - - 5\n6 - x x x x x - - 6\n7 - - - - o - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◉◉◉◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [8, 9, 34, 38, 46, 49, 50, 51, 53, 54]
StringLegalActions() = ["a2", "b2", "c5", "g5", "g6", "b7", "c7", "d7", "f7", "g7"]

# Apply action "f7"
action: 53

# State 14
# Black (x) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - o - - 2
# 3 - x - - - o - - 3
# 4 - o x o o o - - 4
# 5 - - - o x o - - 5
# 6 - x x x o o - - 6
# 7 - - - - o o - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - o - - 2\n3 - x - - - o - - 3\n4 - o x o o o - - 4\n5 - - - o x o - - 5\n6 - x x x o o - - 6\n7 - - - - o o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - o - - 2\n3 - x - - - o - - 3\n4 - o x o o o - - 4\n5 - - - o x o - - 5\n6 - x x x o o - - 6\n7 - - - - o o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◉◉◉◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◉◉◉◯◯◯◯
◉◉◉◉◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [14, 18, 19, 20, 22, 24, 30, 33, 34, 38, 46, 54, 60, 61, 62]
StringLegalActions() = ["g2", "c3", "d3", "e3", "g3", "a4", "g4", "b5", "c5", "g5", "g6", "g7", "e8", "f8", "g8"]

# Apply action "c5"
action: 34

# State 15
# White (o) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - o - - 2
# 3 - x - - - o - - 3
# 4 - o x o o o - - 4
# 5 - - x x x o - - 5
# 6 - x x x o o - - 6
# 7 - - - - o o - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - o - - 2\n3 - x - - - o - - 3\n4 - o x o o o - - 4\n5 - - x x x o - - 5\n6 - x x x o o - - 6\n7 - - - - o o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - o - - 2\n3 - x - - - o - - 3\n4 - o x o o o - - 4\n5 - - x x x o - - 5\n6 - x x x o o - - 6\n7 - - - - o o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◉◉◉◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◉◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◉◉◉◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◉◉◉◯◯◯◯
◉◉◉◉◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [8, 9, 33, 40, 48, 49, 50, 51]
StringLegalActions() = ["a2", "b2", "b5", "a6", "a7", "b7", "c7", "d7"]

# Apply action "a2"
action: 8

# State 16
# Black (x) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 o - - - - o - - 2
# 3 - o - - - o - - 3
# 4 - o o o o o - - 4
# 5 - - x o x o - - 5
# 6 - x x x o o - - 6
# 7 - - - - o o - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 o - - - - o - - 2\n3 - o - - - o - - 3\n4 - o o o o o - - 4\n5 - - x o x o - - 5\n6 - x x x o o - - 6\n7 - - - - o o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 o - - - - o - - 2\n3 - o - - - o - - 3\n4 - o o o o o - - 4\n5 - - x o x o - - 5\n6 - x x x o o - - 6\n7 - - - - o o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◉◯◯◯◯◉◯◯
◉◯◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◯◉◯◯◯  ◯◯◯◉◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◉◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◉◯◉◯◯  ◯◯◉◯◉◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◉◉◉◯◯◯◯
◉◉◉◉◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [14, 16, 18, 19, 20, 22, 38, 46, 54, 60, 61]
StringLegalActions() = ["g2", "a3", "c3", "d3", "e3", "g3", "g5", "g6", "g7", "e8", "f8"]

# Apply action "a3"
action: 16

# State 17
# White (o) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 o - - - - o - - 2
# 3 x o - - - o - - 3
# 4 - x o o o o - - 4
# 5 - - x o x o - - 5
# 6 - x x x o o - - 6
# 7 - - - - o o - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 o - - - - o - - 2\n3 x o - - - o - - 3\n4 - x o o o o - - 4\n5 - - x o x o - - 5\n6 - x x x o o - - 6\n7 - - - - o o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 o - - - - o - - 2\n3 x o - - - o - - 3\n4 - x o o o o - - 4\n5 - - x o x o - - 5\n6 - x x x o o - - 6\n7 - - - - o o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◉◯◯◯◯◉◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◯◉◯◯◯  ◯◯◯◉◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◉◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◉◯◉◯◯  ◯◯◉◯◉◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◉◉◉◯◯◯◯
◉◉◉◉◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [24, 33, 40, 48, 49, 50, 51]
StringLegalActions() = ["a4", "b5", "a6", "a7", "b7", "c7", "d7"]

# Apply action "c7"
action: 50

# State 18
# Black (x) to play:
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 o - - - - o - - 2
# 3 x o - - - o - - 3
# 4 - x o o o o - - 4
# 5 - - o o o o - - 5
# 6 - x o o o o - - 6
# 7 - - o - o o - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 o - - - - o - - 2\n3 x o - - - o - - 3\n4 - x o o o o - - 4\n5 - - o o o o - - 5\n6 - x o o o o - - 6\n7 - - o - o o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 - - - - - - - - 1\n2 o - - - - o - - 2\n3 x o - - - o - - 3\n4 - x o o o o - - 4\n5 - - o o o o - - 5\n6 - x o o o o - - 6\n7 - - o - o o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◉◯◯◯◯◉◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
◉◉◯◉◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◯◉◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◉◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◉◯◯◉◉  ◯◯◉◯◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 9, 18, 20, 30, 46, 59, 61]
StringLegalActions() = ["a1", "b2", "c3", "e3", "g4", "g6", "d8", "f8"]

# Apply action "a1"
action: 0

# State 19
# White (o) to play:
#   a b c d e f g h
# 1 x - - - - - - - 1
# 2 x - - - - o - - 2
# 3 x o - - - o - - 3
# 4 - x o o o o - - 4
# 5 - - o o o o - - 5
# 6 - x o o o o - - 6
# 7 - - o - o o - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x o - - - o - - 3\n4 - x o o o o - - 4\n5 - - o o o o - - 5\n6 - x o o o o - - 6\n7 - - o - o o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x o - - - o - - 3\n4 - x o o o o - - 4\n5 - - o o o o - - 5\n6 - x o o o o - - 6\n7 - - o - o o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
◉◉◯◉◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◯◉◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◉◯◯◉◉  ◯◯◉◯◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [24, 32, 33, 40, 48]
StringLegalActions() = ["a4", "a5", "b5", "a6", "a7"]

# Apply action "a7"
action: 48

# State 20
# Black (x) to play:
#   a b c d e f g h
# 1 x - - - - - - - 1
# 2 x - - - - o - - 2
# 3 x o - - - o - - 3
# 4 - x o o o o - - 4
# 5 - - o o o o - - 5
# 6 - o o o o o - - 6
# 7 o - o - o o - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x o - - - o - - 3\n4 - x o o o o - - 4\n5 - - o o o o - - 5\n6 - o o o o o - - 6\n7 o - o - o o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x o - - - o - - 3\n4 - x o o o o - - 4\n5 - - o o o o - - 5\n6 - o o o o o - - 6\n7 o - o - o o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◯◉◯◉◯◯◉◉  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◯◉◯◉◯◯◉◉  ◉◯◉◯◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [9, 18, 30, 61, 62]
StringLegalActions() = ["b2", "c3", "g4", "f8", "g8"]

# Apply action "f8"
action: 61

# State 21
# White (o) to play:
#   a b c d e f g h
# 1 x - - - - - - - 1
# 2 x - - - - o - - 2
# 3 x o - - - o - - 3
# 4 - x o o o o - - 4
# 5 - - x o o o - - 5
# 6 - o o x o o - - 6
# 7 o - o - x o - - 7
# 8 - - - - - x - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x o - - - o - - 3\n4 - x o o o o - - 4\n5 - - x o o o - - 5\n6 - o o x o o - - 6\n7 o - o - x o - - 7\n8 - - - - - x - - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x o - - - o - - 3\n4 - x o o o o - - 4\n5 - - x o o o - - 5\n6 - o o x o o - - 6\n7 o - o - x o - - 7\n8 - - - - - x - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◉◯◯◯◯  ◯◉◉◯◉◉◯◯
◯◉◯◉◯◯◉◉  ◯◯◯◯◉◯◯◯  ◉◯◉◯◯◉◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◯◉◉◯◯  ◯◯◯◉◯◯◯◯
◯◉◯◉◯◯◉◉  ◉◯◉◯◯◉◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [24, 33, 51, 59, 60]
StringLegalActions() = ["a4", "b5", "d7", "d8", "e8"]

# Apply action "e8"
action: 60

# State 22
# Black (x) to play:
#   a b c d e f g h
# 1 x - - - - - - - 1
# 2 x - - - - o - - 2
# 3 x o - - - o - - 3
# 4 - x o o o o - - 4
# 5 - - x o o o - - 5
# 6 - o o x o o - - 6
# 7 o - o - o o - - 7
# 8 - - - - o x - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x o - - - o - - 3\n4 - x o o o o - - 4\n5 - - x o o o - - 5\n6 - o o x o o - - 6\n7 o - o - o o - - 7\n8 - - - - o x - - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x o - - - o - - 3\n4 - x o o o o - - 4\n5 - - x o o o - - 5\n6 - o o x o o - - 6\n7 o - o - o o - - 7\n8 - - - - o x - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◉◯◯◯◯  ◯◉◉◯◉◉◯◯
◯◉◯◉◯◯◉◉  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◉◯◯
◉◉◉◉◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◉◯◯◯
ObservationTensor(1):
◯◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◯◉◉◯◯  ◯◯◯◉◯◯◯◯
◯◉◯◉◯◯◉◉  ◉◯◉◯◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◯◯◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [5, 9, 18, 19, 20, 22, 30, 38, 40, 46, 57, 58, 59, 62]
StringLegalActions() = ["f1", "b2", "c3", "d3", "e3", "g3", "g4", "g5", "a6", "g6", "b8", "c8", "d8", "g8"]

# Apply action "d8"
action: 59

# State 23
# White (o) to play:
#   a b c d e f g h
# 1 x - - - - - - - 1
# 2 x - - - - o - - 2
# 3 x o - - - o - - 3
# 4 - x o o o o - - 4
# 5 - - x o o o - - 5
# 6 - o o x o o - - 6
# 7 o - o - o o - - 7
# 8 - - - x x x - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x o - - - o - - 3\n4 - x o o o o - - 4\n5 - - x o o o - - 5\n6 - o o x o o - - 6\n7 o - o - o o - - 7\n8 - - - x x x - - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x o - - - o - - 3\n4 - x o o o o - - 4\n5 - - x o o o - - 5\n6 - o o x o o - - 6\n7 o - o - o o - - 7\n8 - - - x x x - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◉◯◯◯◯  ◯◉◉◯◉◉◯◯
◯◉◯◉◯◯◉◉  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◉◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◉◉◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◯◉◉◯◯  ◯◯◯◉◯◯◯◯
◯◉◯◉◯◯◉◉  ◉◯◉◯◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [24, 33, 51]
StringLegalActions() = ["a4", "b5", "d7"]

# Apply action "b5"
action: 33

# State 24
# Black (x) to play:
#   a b c d e f g h
# 1 x - - - - - - - 1
# 2 x - - - - o - - 2
# 3 x o - - - o - - 3
# 4 - o o o o o - - 4
# 5 - o o o o o - - 5
# 6 - o o x o o - - 6
# 7 o - o - o o - - 7
# 8 - - - x x x - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x o - - - o - - 3\n4 - o o o o o - - 4\n5 - o o o o o - - 5\n6 - o o x o o - - 6\n7 o - o - o o - - 7\n8 - - - x x x - - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x o - - - o - - 3\n4 - o o o o o - - 4\n5 - o o o o o - - 5\n6 - o o x o o - - 6\n7 o - o - o o - - 7\n8 - - - x x x - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◉◯◯◯◯  ◯◉◉◯◉◉◯◯
◯◉◯◉◯◯◉◉  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◉◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◉◉◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◯◉◉◯◯  ◯◯◯◉◯◯◯◯
◯◉◯◉◯◯◉◉  ◉◯◉◯◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [5, 18, 19, 20, 22, 32, 38, 40, 46, 57, 62]
StringLegalActions() = ["f1", "c3", "d3", "e3", "g3", "a5", "g5", "a6", "g6", "b8", "g8"]

# Apply action "c3"
action: 18

# State 25
# White (o) to play:
#   a b c d e f g h
# 1 x - - - - - - - 1
# 2 x - - - - o - - 2
# 3 x x x - - o - - 3
# 4 - o o o o o - - 4
# 5 - o o o o o - - 5
# 6 - o o x o o - - 6
# 7 o - o - o o - - 7
# 8 - - - x x x - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x x x - - o - - 3\n4 - o o o o o - - 4\n5 - o o o o o - - 5\n6 - o o x o o - - 6\n7 o - o - o o - - 7\n8 - - - x x x - - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x x x - - o - - 3\n4 - o o o o o - - 4\n5 - o o o o o - - 5\n6 - o o x o o - - 6\n7 o - o - o o - - 7\n8 - - - x x x - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◯◉◉◯◉◉  ◉◉◉◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◉◯◯◯◯  ◯◉◉◯◉◉◯◯
◯◉◯◉◯◯◉◉  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◉◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◉◉◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◉◉◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◯◉◉◯◯  ◯◯◯◉◯◯◯◯
◯◉◯◉◯◯◉◉  ◉◯◉◯◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [9, 10, 11, 51]
StringLegalActions() = ["b2", "c2", "d2", "d7"]

# Apply action "d7"
action: 51

# State 26
# Black (x) to play:
#   a b c d e f g h
# 1 x - - - - - - - 1
# 2 x - - - - o - - 2
# 3 x x x - - o - - 3
# 4 - o o o o o - - 4
# 5 - o o o o o - - 5
# 6 - o o o o o - - 6
# 7 o - o o o o - - 7
# 8 - - - x x x - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x x x - - o - - 3\n4 - o o o o o - - 4\n5 - o o o o o - - 5\n6 - o o o o o - - 6\n7 o - o o o o - - 7\n8 - - - x x x - - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x x x - - o - - 3\n4 - o o o o o - - 4\n5 - o o o o o - - 5\n6 - o o o o o - - 6\n7 o - o o o o - - 7\n8 - - - x x x - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◯◉◉◯◉◉  ◉◉◉◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◯◉◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◉◯◉◉◉◉◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◉◉◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◉◉◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◉◉  ◉◯◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [5, 19, 20, 24, 32, 38, 46, 49, 54, 58, 62]
StringLegalActions() = ["f1", "d3", "e3", "a4", "a5", "g5", "g6", "b7", "g7", "c8", "g8"]

# Apply action "c8"
action: 58

# State 27
# White (o) to play:
#   a b c d e f g h
# 1 x - - - - - - - 1
# 2 x - - - - o - - 2
# 3 x x x - - o - - 3
# 4 - o x o o o - - 4
# 5 - o x o o o - - 5
# 6 - o x o o o - - 6
# 7 o - x o o o - - 7
# 8 - - x x x x - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x x x - - o - - 3\n4 - o x o o o - - 4\n5 - o x o o o - - 5\n6 - o x o o o - - 6\n7 o - x o o o - - 7\n8 - - x x x x - - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x - - - - o - - 2\n3 x x x - - o - - 3\n4 - o x o o o - - 4\n5 - o x o o o - - 5\n6 - o x o o o - - 6\n7 o - x o o o - - 7\n8 - - x x x x - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◯◉◉◯◉◉  ◉◉◉◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◯◉◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◉◯◯◉◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◉◉◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◯◉◯◯◯◯◉◉  ◉◯◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [9, 11, 19, 49, 57]
StringLegalActions() = ["b2", "d2", "d3", "b7", "b8"]

# Apply action "b2"
action: 9

# State 28
# Black (x) to play:
#   a b c d e f g h
# 1 x - - - - - - - 1
# 2 x o - - - o - - 2
# 3 x o o - - o - - 3
# 4 - o x o o o - - 4
# 5 - o x o o o - - 5
# 6 - o x o o o - - 6
# 7 o - x o o o - - 7
# 8 - - x x x x - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 - o x o o o - - 5\n6 - o x o o o - - 6\n7 o - x o o o - - 7\n8 - - x x x x - - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x - - - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 - o x o o o - - 5\n6 - o x o o o - - 6\n7 o - x o o o - - 7\n8 - - x x x x - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◯◯◯◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◯◉◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◉◯◯◉◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◉◉◯◉◉  ◯◉◉◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◯◉◯◯◯◯◉◉  ◉◯◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 5, 10, 14, 19, 20, 22, 24, 30, 32, 38, 40, 46, 54, 62]
StringLegalActions() = ["c1", "f1", "c2", "g2", "d3", "e3", "g3", "a4", "g4", "a5", "g5", "a6", "g6", "g7", "g8"]

# Apply action "c1"
action: 2

# State 29
# White (o) to play:
#   a b c d e f g h
# 1 x - x - - - - - 1
# 2 x x - - - o - - 2
# 3 x o o - - o - - 3
# 4 - o x o o o - - 4
# 5 - o x o o o - - 5
# 6 - o x o o o - - 6
# 7 o - x o o o - - 7
# 8 - - x x x x - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x - x - - - - - 1\n2 x x - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 - o x o o o - - 5\n6 - o x o o o - - 6\n7 o - x o o o - - 7\n8 - - x x x x - - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x - x - - - - - 1\n2 x x - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 - o x o o o - - 5\n6 - o x o o o - - 6\n7 o - x o o o - - 7\n8 - - x x x x - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◉◯◉◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◉◉◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◯◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◯◉◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◉◯◯◉◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◉◉◯◯◯◯◯◯
◯◯◯◉◉◯◉◉  ◯◉◉◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◯◉◯◯◯◯◉◉  ◉◯◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 19, 49, 57]
StringLegalActions() = ["b1", "d3", "b7", "b8"]

# Apply action "b7"
action: 49

# State 30
# Black (x) to play:
#   a b c d e f g h
# 1 x - x - - - - - 1
# 2 x x - - - o - - 2
# 3 x o o - - o - - 3
# 4 - o x o o o - - 4
# 5 - o x o o o - - 5
# 6 - o o o o o - - 6
# 7 o o o o o o - - 7
# 8 - - x x x x - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x - x - - - - - 1\n2 x x - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 - o x o o o - - 5\n6 - o o o o o - - 6\n7 o o o o o o - - 7\n8 - - x x x x - - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x - x - - - - - 1\n2 x x - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 - o x o o o - - 5\n6 - o o o o o - - 6\n7 o o o o o o - - 7\n8 - - x x x x - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◉◯◉◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◉◉◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◯◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◉◉◯◯◯◯◯◯
◯◯◯◉◉◯◉◉  ◯◉◉◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [5, 10, 19, 20, 24, 30, 32, 38, 40, 46, 54, 57, 62]
StringLegalActions() = ["f1", "c2", "d3", "e3", "a4", "g4", "a5", "g5", "a6", "g6", "g7", "b8", "g8"]

# Apply action "g8"
action: 62

# State 31
# White (o) to play:
#   a b c d e f g h
# 1 x - x - - - - - 1
# 2 x x - - - o - - 2
# 3 x o o - - o - - 3
# 4 - o x o o o - - 4
# 5 - o x x o o - - 5
# 6 - o o o x o - - 6
# 7 o o o o o x - - 7
# 8 - - x x x x x - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x - x - - - - - 1\n2 x x - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 - o x x o o - - 5\n6 - o o o x o - - 6\n7 o o o o o x - - 7\n8 - - x x x x x - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x - x - - - - - 1\n2 x x - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 - o x x o o - - 5\n6 - o o o x o - - 6\n7 o o o o o x - - 7\n8 - - x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◉◯◉◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◉◉◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◯◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◉◯◯◯◯  ◯◉◯◯◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◉◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◯◯
◉◉◯◯◯◯◯◉  ◯◯◉◉◉◉◉◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◉◉◯◯◯◯◯◯
◯◯◯◉◉◯◉◉  ◯◉◉◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◯◉◉◯◯  ◯◯◉◉◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 19, 54]
StringLegalActions() = ["b1", "d3", "g7"]

# Apply action "b1"
action: 1

# State 32
# Black (x) to play:
#   a b c d e f g h
# 1 x o x - - - - - 1
# 2 x o - - - o - - 2
# 3 x o o - - o - - 3
# 4 - o x o o o - - 4
# 5 - o x x o o - - 5
# 6 - o o o x o - - 6
# 7 o o o o o x - - 7
# 8 - - x x x x x - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x o x - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 - o x x o o - - 5\n6 - o o o x o - - 6\n7 o o o o o x - - 7\n8 - - x x x x x - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x o x - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 - o x x o o - - 5\n6 - o o o x o - - 6\n7 o o o o o x - - 7\n8 - - x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◉◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◯◯◯◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◉◯◯◯◯  ◯◉◯◯◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◉◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◯◯
◉◉◯◯◯◯◯◉  ◯◯◉◉◉◉◉◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◉◉◯◉◉  ◯◉◉◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◯◉◉◯◯  ◯◯◉◉◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [5, 10, 14, 19, 20, 24, 30, 32, 38, 40, 46, 54, 56]
StringLegalActions() = ["f1", "c2", "g2", "d3", "e3", "a4", "g4", "a5", "g5", "a6", "g6", "g7", "a8"]

# Apply action "a6"
action: 40

# State 33
# White (o) to play:
#   a b c d e f g h
# 1 x o x - - - - - 1
# 2 x o - - - o - - 2
# 3 x o o - - o - - 3
# 4 - o x o o o - - 4
# 5 - x x x o o - - 5
# 6 x x x x x o - - 6
# 7 o x o o o x - - 7
# 8 - - x x x x x - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x o x - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 - x x x o o - - 5\n6 x x x x x o - - 6\n7 o x o o o x - - 7\n8 - - x x x x x - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x o x - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 - x x x o o - - 5\n6 x x x x x o - - 6\n7 o x o o o x - - 7\n8 - - x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◉◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◯◯◯◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◉◉◉◯◯◯
◉◉◯◯◯◯◯◉  ◯◯◉◉◉◉◉◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◉◉◯◉◉  ◯◉◉◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◉◉  ◉◯◉◉◉◯◯◯  ◯◉◯◯◯◉◯◯
◉◉◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [3, 24, 32, 54, 56, 57]
StringLegalActions() = ["d1", "a4", "a5", "g7", "a8", "b8"]

# Apply action "g7"
action: 54

# State 34
# Black (x) to play:
#   a b c d e f g h
# 1 x o x - - - - - 1
# 2 x o - - - o - - 2
# 3 x o o - - o - - 3
# 4 - o x o o o - - 4
# 5 - x x x o o - - 5
# 6 x x x x x o - - 6
# 7 o x o o o o o - 7
# 8 - - x x x x x - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x o x - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 - x x x o o - - 5\n6 x x x x x o - - 6\n7 o x o o o o o - 7\n8 - - x x x x x - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x o x - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 - x x x o o - - 5\n6 x x x x x o - - 6\n7 o x o o o o o - 7\n8 - - x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◉◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◯◯◯◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◉◉◉◯
◉◉◯◯◯◯◯◉  ◯◯◉◉◉◉◉◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◉◉◯◉◉  ◯◉◉◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◉◉◉◉◉◯  ◯◉◯◯◯◯◯◯
◉◉◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [5, 10, 14, 19, 20, 22, 24, 30, 38, 46, 47, 55, 56, 57, 63]
StringLegalActions() = ["f1", "c2", "g2", "d3", "e3", "g3", "a4", "g4", "g5", "g6", "h6", "h7", "a8", "b8", "h8"]

# Apply action "a8"
action: 56

# State 35
# White (o) to play:
#   a b c d e f g h
# 1 x o x - - - - - 1
# 2 x o - - - o - - 2
# 3 x o o - - o - - 3
# 4 - o x o o o - - 4
# 5 - x x x o o - - 5
# 6 x x x x x o - - 6
# 7 x x o o o o o - 7
# 8 x - x x x x x - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x o x - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 - x x x o o - - 5\n6 x x x x x o - - 6\n7 x x o o o o o - 7\n8 x - x x x x x - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x o x - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 - x x x o o - - 5\n6 x x x x x o - - 6\n7 x x o o o o o - 7\n8 x - x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◉◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◯◯◯◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◯◯◯◯◯◯  ◯◯◉◉◉◉◉◯
◯◉◯◯◯◯◯◉  ◉◯◉◉◉◉◉◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◉◉◯◉◉  ◯◉◉◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◉◉◉◉◉◯  ◉◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◉◯◉◉◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [3, 24, 32, 57]
StringLegalActions() = ["d1", "a4", "a5", "b8"]

# Apply action "a5"
action: 32

# State 36
# Black (x) to play:
#   a b c d e f g h
# 1 x o x - - - - - 1
# 2 x o - - - o - - 2
# 3 x o o - - o - - 3
# 4 - o x o o o - - 4
# 5 o o o o o o - - 5
# 6 x o x x x o - - 6
# 7 x x o o o o o - 7
# 8 x - x x x x x - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x o x - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 o o o o o o - - 5\n6 x o x x x o - - 6\n7 x x o o o o o - 7\n8 x - x x x x x - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x o x - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o - - 3\n4 - o x o o o - - 4\n5 o o o o o o - - 5\n6 x o x x x o - - 6\n7 x x o o o o o - 7\n8 x - x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◉◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◯◯◯◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◉◉  ◉◯◉◉◉◯◯◯  ◯◉◯◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◯◯◯◯◯◯  ◯◯◉◉◉◉◉◯
◯◉◯◯◯◯◯◉  ◉◯◉◉◉◉◉◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◉◉◯◉◉  ◯◉◉◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◉◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◉◉◉◉◉◯  ◉◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◉◯◉◉◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [5, 10, 14, 19, 20, 22, 24, 30, 38, 46, 47, 55, 57, 63]
StringLegalActions() = ["f1", "c2", "g2", "d3", "e3", "g3", "a4", "g4", "g5", "g6", "h6", "h7", "b8", "h8"]

# Apply action "g3"
action: 22

# State 37
# White (o) to play:
#   a b c d e f g h
# 1 x o x - - - - - 1
# 2 x o - - - o - - 2
# 3 x o o - - o x - 3
# 4 - o x o o x - - 4
# 5 o o o o x o - - 5
# 6 x o x x x o - - 6
# 7 x x o o o o o - 7
# 8 x - x x x x x - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x o x - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o x - 3\n4 - o x o o x - - 4\n5 o o o o x o - - 5\n6 x o x x x o - - 6\n7 x x o o o o o - 7\n8 x - x x x x x - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x o x - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o x - 3\n4 - o x o o x - - 4\n5 o o o o x o - - 5\n6 x o x x x o - - 6\n7 x x o o o o o - 7\n8 x - x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◉◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◯◯◯◉◉◯◯◉  ◉◯◯◯◯◯◉◯  ◯◉◉◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◉◯◯  ◯◉◯◉◉◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◉◯◯
◯◯◯◯◯◯◉◉  ◉◯◉◉◉◯◯◯  ◯◉◯◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◯◯◯◯◯◯  ◯◯◉◉◉◉◉◯
◯◉◯◯◯◯◯◉  ◉◯◉◉◉◉◉◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◉◉◯◯◉  ◯◉◉◯◯◉◯◯  ◉◯◯◯◯◯◉◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◯◯◯  ◯◯◉◯◯◉◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◉◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◉◉◉◉◉◯  ◉◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◉◯◉◉◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [3, 15, 19, 23, 30, 31, 57]
StringLegalActions() = ["d1", "h2", "d3", "h3", "g4", "h4", "b8"]

# Apply action "b8"
action: 57

# State 38
# Black (x) to play:
#   a b c d e f g h
# 1 x o x - - - - - 1
# 2 x o - - - o - - 2
# 3 x o o - - o x - 3
# 4 - o x o o x - - 4
# 5 o o o o x o - - 5
# 6 x o x x x o - - 6
# 7 x o o o o o o - 7
# 8 x o x x x x x - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x o x - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o x - 3\n4 - o x o o x - - 4\n5 o o o o x o - - 5\n6 x o x x x o - - 6\n7 x o o o o o o - 7\n8 x o x x x x x - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x o x - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o x - 3\n4 - o x o o x - - 4\n5 o o o o x o - - 5\n6 x o x x x o - - 6\n7 x o o o o o o - 7\n8 x o x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◉◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◯◯◯◉◉◯◯◉  ◉◯◯◯◯◯◉◯  ◯◉◉◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◉◯◯  ◯◉◯◉◉◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◉◯◯
◯◯◯◯◯◯◉◉  ◉◯◉◉◉◯◯◯  ◯◉◯◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◉  ◉◯◉◉◉◉◉◯  ◯◉◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◉◉◯◯◉  ◯◉◉◯◯◉◯◯  ◉◯◯◯◯◯◉◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◯◯◯  ◯◯◉◯◯◉◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◉◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 5, 10, 14, 19, 20, 24, 30, 38, 46, 47, 55, 63]
StringLegalActions() = ["e1", "f1", "c2", "g2", "d3", "e3", "a4", "g4", "g5", "g6", "h6", "h7", "h8"]

# Apply action "g5"
action: 38

# State 39
# White (o) to play:
#   a b c d e f g h
# 1 x o x - - - - - 1
# 2 x o - - - o - - 2
# 3 x o o - - o x - 3
# 4 - o x o o x - - 4
# 5 o o o o x x x - 5
# 6 x o x x x x - - 6
# 7 x o o o x o o - 7
# 8 x o x x x x x - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x o x - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o x - 3\n4 - o x o o x - - 4\n5 o o o o x x x - 5\n6 x o x x x x - - 6\n7 x o o o x o o - 7\n8 x o x x x x x - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x o x - - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o x - 3\n4 - o x o o x - - 4\n5 o o o o x x x - 5\n6 x o x x x x - - 6\n7 x o o o x o o - 7\n8 x o x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◉◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◯◯◯◉◉◯◯◉  ◉◯◯◯◯◯◉◯  ◯◉◉◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◉◯◯  ◯◉◯◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◉◉◉◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◯
◯◯◯◯◯◯◯◉  ◉◯◉◉◉◉◉◯  ◯◉◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◉◉◯◯◉  ◯◉◉◯◯◉◯◯  ◉◯◯◯◯◯◉◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◯◯◯  ◯◯◉◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◉◯
◯◯◯◯◯◯◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◉◉◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◯◉◉◯  ◉◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [3, 15, 19, 23, 30, 31, 39, 46, 63]
StringLegalActions() = ["d1", "h2", "d3", "h3", "g4", "h4", "h5", "g6", "h8"]

# Apply action "d1"
action: 3

# State 40
# Black (x) to play:
#   a b c d e f g h
# 1 x o o o - - - - 1
# 2 x o - - - o - - 2
# 3 x o o - - o x - 3
# 4 - o x o o x - - 4
# 5 o o o o x x x - 5
# 6 x o x x x x - - 6
# 7 x o o o x o o - 7
# 8 x o x x x x x - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o x - 3\n4 - o x o o x - - 4\n5 o o o o x x x - 5\n6 x o x x x x - - 6\n7 x o o o x o o - 7\n8 x o x x x x x - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - - o - - 2\n3 x o o - - o x - 3\n4 - o x o o x - - 4\n5 o o o o x x x - 5\n6 x o x x x x - - 6\n7 x o o o x o o - 7\n8 x o x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◉◉◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◯
◯◯◯◉◉◯◯◉  ◉◯◯◯◯◯◉◯  ◯◉◉◯◯◉◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◯◉◯◯  ◯◉◯◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◉◉◉◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◯
◯◯◯◯◯◯◯◉  ◉◯◉◉◉◉◉◯  ◯◉◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◉◯◉◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◉◉◯◯◉  ◯◉◉◯◯◉◯◯  ◉◯◯◯◯◯◉◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◉◯◯◯  ◯◯◉◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◉◯
◯◯◯◯◯◯◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◉◉◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◯◉◉◯  ◉◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 5, 10, 14, 19, 20, 24, 46, 47, 55, 63]
StringLegalActions() = ["e1", "f1", "c2", "g2", "d3", "e3", "a4", "g6", "h6", "h7", "h8"]

# Apply action "g2"
action: 14

# State 41
# White (o) to play:
#   a b c d e f g h
# 1 x o o o - - - - 1
# 2 x o - - - o x - 2
# 3 x o o - - x x - 3
# 4 - o x o x x - - 4
# 5 o o o x x x x - 5
# 6 x o x x x x - - 6
# 7 x o o o x o o - 7
# 8 x o x x x x x - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - - o x - 2\n3 x o o - - x x - 3\n4 - o x o x x - - 4\n5 o o o x x x x - 5\n6 x o x x x x - - 6\n7 x o o o x o o - 7\n8 x o x x x x x - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - - o x - 2\n3 x o o - - x x - 3\n4 - o x o x x - - 4\n5 o o o x x x x - 5\n6 x o x x x x - - 6\n7 x o o o x o o - 7\n8 x o x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◉◉◉◯◯◉  ◉◯◯◯◯◯◉◯  ◯◉◯◯◯◉◯◯
◯◯◯◉◉◯◯◉  ◉◯◯◯◯◉◉◯  ◯◉◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◉◉◯◯  ◯◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◉◉◉◉◯  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◯
◯◯◯◯◯◯◯◉  ◉◯◉◉◉◉◉◯  ◯◉◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◉◯◯◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◉◯
◯◯◯◉◉◯◯◉  ◯◉◉◯◯◯◯◯  ◉◯◯◯◯◉◉◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◯◯◯◯  ◯◯◉◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◉◉◯
◯◯◯◯◯◯◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◉◉◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◯◉◉◯  ◉◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [7, 15, 19, 30, 31, 39, 46, 63]
StringLegalActions() = ["h1", "h2", "d3", "g4", "h4", "h5", "g6", "h8"]

# Apply action "d3"
action: 19

# State 42
# Black (x) to play:
#   a b c d e f g h
# 1 x o o o - - - - 1
# 2 x o - - - o x - 2
# 3 x o o o - x x - 3
# 4 - o o o x x - - 4
# 5 o o o x x x x - 5
# 6 x o x x x x - - 6
# 7 x o o o x o o - 7
# 8 x o x x x x x - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - - o x - 2\n3 x o o o - x x - 3\n4 - o o o x x - - 4\n5 o o o x x x x - 5\n6 x o x x x x - - 6\n7 x o o o x o o - 7\n8 x o x x x x x - 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - - o x - 2\n3 x o o o - x x - 3\n4 - o o o x x - - 4\n5 o o o x x x x - 5\n6 x o x x x x - - 6\n7 x o o o x o o - 7\n8 x o x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◉◉◉◯◯◉  ◉◯◯◯◯◯◉◯  ◯◉◯◯◯◉◯◯
◯◯◯◯◉◯◯◉  ◉◯◯◯◯◉◉◯  ◯◉◉◉◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◉◉◉◉◯  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◯
◯◯◯◯◯◯◯◉  ◉◯◉◉◉◉◉◯  ◯◉◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◉◯◯◉  ◯◉◯◯◯◉◯◯  ◉◯◯◯◯◯◉◯
◯◯◯◯◉◯◯◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◉◉◯
◉◯◯◯◯◯◉◉  ◯◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◉◉◯
◯◯◯◯◯◯◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◉◉◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◯◉◉◯  ◉◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 5, 10, 11, 12, 20, 24, 46, 47, 55, 63]
StringLegalActions() = ["e1", "f1", "c2", "d2", "e2", "e3", "a4", "g6", "h6", "h7", "h8"]

# Apply action "e2"
action: 12

# State 43
# White (o) to play:
#   a b c d e f g h
# 1 x o o o - - - - 1
# 2 x o - - x x x - 2
# 3 x o o x - x x - 3
# 4 - o x o x x - - 4
# 5 o x o x x x x - 5
# 6 x o x x x x - - 6
# 7 x o o o x o o - 7
# 8 x o x x x x x - 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - x x x - 2\n3 x o o x - x x - 3\n4 - o x o x x - - 4\n5 o x o x x x x - 5\n6 x o x x x x - - 6\n7 x o o o x o o - 7\n8 x o x x x x x - 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - x x x - 2\n3 x o o x - x x - 3\n4 - o x o x x - - 4\n5 o x o x x x x - 5\n6 x o x x x x - - 6\n7 x o o o x o o - 7\n8 x o x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◉◉◯◯◯◉  ◉◯◯◯◉◉◉◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◉◯◯◉  ◉◯◯◉◯◉◉◯  ◯◉◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◉◉◯◯  ◯◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◯◉◉◉◉◯  ◉◯◉◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◯
◯◯◯◯◯◯◯◉  ◉◯◉◉◉◉◉◯  ◯◉◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◯◯◯◉  ◯◉◯◯◯◯◯◯  ◉◯◯◯◉◉◉◯
◯◯◯◯◉◯◯◉  ◯◉◉◯◯◯◯◯  ◉◯◯◉◯◉◉◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◯◯◯◯  ◯◯◉◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◯◉◯◯◯◯◯  ◯◉◯◉◉◉◉◯
◯◯◯◯◯◯◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◉◉◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◯◉◉◯  ◉◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [5, 7, 11, 15, 20, 24, 30, 39, 46, 63]
StringLegalActions() = ["f1", "h1", "d2", "h2", "e3", "a4", "g4", "h5", "g6", "h8"]

# Apply action "h8"
action: 63

# State 44
# Black (x) to play:
#   a b c d e f g h
# 1 x o o o - - - - 1
# 2 x o - - x x x - 2
# 3 x o o x - x x - 3
# 4 - o x o x x - - 4
# 5 o x o x x x x - 5
# 6 x o x x x x - - 6
# 7 x o o o x o o - 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - x x x - 2\n3 x o o x - x x - 3\n4 - o x o x x - - 4\n5 o x o x x x x - 5\n6 x o x x x x - - 6\n7 x o o o x o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - x x x - 2\n3 x o o x - x x - 3\n4 - o x o x x - - 4\n5 o x o x x x x - 5\n6 x o x x x x - - 6\n7 x o o o x o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◉◉◯◯◯◉  ◉◯◯◯◉◉◉◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◉◯◯◉  ◉◯◯◉◯◉◉◯  ◯◉◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◯◉◉◯◯  ◯◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◯◉◉◉◉◯  ◉◯◉◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◯◯◯◉  ◯◉◯◯◯◯◯◯  ◉◯◯◯◉◉◉◯
◯◯◯◯◉◯◯◉  ◯◉◉◯◯◯◯◯  ◉◯◯◉◯◉◉◯
◉◯◯◯◯◯◉◉  ◯◉◯◉◯◯◯◯  ◯◯◉◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◯◉◯◯◯◯◯  ◯◉◯◉◉◉◉◯
◯◯◯◯◯◯◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◉◉◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◯◉◉◯  ◉◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 10, 20, 24, 55]
StringLegalActions() = ["e1", "c2", "e3", "a4", "h7"]

# Apply action "e3"
action: 20

# State 45
# White (o) to play:
#   a b c d e f g h
# 1 x o o o - - - - 1
# 2 x o - - x x x - 2
# 3 x o o x x x x - 3
# 4 - o x x x x - - 4
# 5 o x x x x x x - 5
# 6 x x x x x x - - 6
# 7 x o o o x o o - 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63, 20]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - x x x - 2\n3 x o o x x x x - 3\n4 - o x x x x - - 4\n5 o x x x x x x - 5\n6 x x x x x x - - 6\n7 x o o o x o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - x x x - 2\n3 x o o x x x x - 3\n4 - o x x x x - - 4\n5 o x x x x x x - 5\n6 x x x x x x - - 6\n7 x o o o x o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◉◉◯◯◯◉  ◉◯◯◯◉◉◉◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◉◉◉◉◯  ◯◉◉◯◯◯◯◯
◉◯◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◯◯◯◉  ◯◉◯◯◯◯◯◯  ◉◯◯◯◉◉◉◯
◯◯◯◯◯◯◯◉  ◯◉◉◯◯◯◯◯  ◉◯◯◉◉◉◉◯
◉◯◯◯◯◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◯◉◉◯  ◉◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 5, 7, 11, 15, 23, 24, 30, 31, 39]
StringLegalActions() = ["e1", "f1", "h1", "d2", "h2", "h3", "a4", "g4", "h4", "h5"]

# Apply action "h4"
action: 31

# State 46
# Black (x) to play:
#   a b c d e f g h
# 1 x o o o - - - - 1
# 2 x o - - x x x - 2
# 3 x o o x x x x - 3
# 4 - o x x x x - o 4
# 5 o x x x x x o - 5
# 6 x x x x x o - - 6
# 7 x o o o o o o - 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63, 20, 31]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - x x x - 2\n3 x o o x x x x - 3\n4 - o x x x x - o 4\n5 o x x x x x o - 5\n6 x x x x x o - - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - x x x - 2\n3 x o o x x x x - 3\n4 - o x x x x - o 4\n5 o x x x x x o - 5\n6 x x x x x o - - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◉◉◯◯◯◉  ◉◯◯◯◉◉◉◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◉◉◉◉◯  ◯◉◉◯◯◯◯◯
◉◯◯◯◯◯◉◯  ◯◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◉
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◯◯  ◉◯◯◯◯◯◉◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◯◯◯◉  ◯◉◯◯◯◯◯◯  ◉◯◯◯◉◉◉◯
◯◯◯◯◯◯◯◉  ◯◉◉◯◯◯◯◯  ◉◯◯◉◉◉◉◯
◉◯◯◯◯◯◉◯  ◯◉◯◯◯◯◯◉  ◯◯◉◉◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◉◯  ◯◉◉◉◉◉◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 10, 24, 39, 46, 47, 55]
StringLegalActions() = ["e1", "c2", "a4", "h5", "g6", "h6", "h7"]

# Apply action "h5"
action: 39

# State 47
# White (o) to play:
#   a b c d e f g h
# 1 x o o o - - - - 1
# 2 x o - - x x x - 2
# 3 x o o x x x x - 3
# 4 - o x x x x - o 4
# 5 o x x x x x x x 5
# 6 x x x x x o - - 6
# 7 x o o o o o o - 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63, 20, 31, 39]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - x x x - 2\n3 x o o x x x x - 3\n4 - o x x x x - o 4\n5 o x x x x x x x 5\n6 x x x x x o - - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - x x x - 2\n3 x o o x x x x - 3\n4 - o x x x x - o 4\n5 o x x x x x x x 5\n6 x x x x x o - - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◉◉◯◯◯◉  ◉◯◯◯◉◉◉◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◉◉◉◉◯  ◯◉◉◯◯◯◯◯
◉◯◯◯◯◯◉◯  ◯◯◉◉◉◉◯◯  ◯◉◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◯◯◯◉  ◯◉◯◯◯◯◯◯  ◉◯◯◯◉◉◉◯
◯◯◯◯◯◯◯◉  ◯◉◉◯◯◯◯◯  ◉◯◯◉◉◉◉◯
◉◯◯◯◯◯◉◯  ◯◉◯◯◯◯◯◉  ◯◯◉◉◉◉◯◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
◯◯◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 5, 7, 11, 15, 23, 24, 30, 47]
StringLegalActions() = ["e1", "f1", "h1", "d2", "h2", "h3", "a4", "g4", "h6"]

# Apply action "a4"
action: 24

# State 48
# Black (x) to play:
#   a b c d e f g h
# 1 x o o o - - - - 1
# 2 x o - - x x x - 2
# 3 x o o x x x x - 3
# 4 o o x x x x - o 4
# 5 o o x x x x x x 5
# 6 x x o x x o - - 6
# 7 x o o o o o o - 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63, 20, 31, 39, 24]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - x x x - 2\n3 x o o x x x x - 3\n4 o o x x x x - o 4\n5 o o x x x x x x 5\n6 x x o x x o - - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - x x x - 2\n3 x o o x x x x - 3\n4 o o x x x x - o 4\n5 o o x x x x x x 5\n6 x x o x x o - - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◉◉◯◯◯◉  ◉◯◯◯◉◉◉◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◉◉◉◉◯  ◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◉◯  ◯◯◉◉◉◉◯◯  ◉◉◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◉◉◉◉◉◉  ◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◯◯◯◉  ◯◉◯◯◯◯◯◯  ◉◯◯◯◉◉◉◯
◯◯◯◯◯◯◯◉  ◯◉◉◯◯◯◯◯  ◉◯◯◉◉◉◉◯
◯◯◯◯◯◯◉◯  ◉◉◯◯◯◯◯◉  ◯◯◉◉◉◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯  ◯◯◉◉◉◉◉◉
◯◯◯◯◯◯◉◉  ◯◯◉◯◯◉◯◯  ◉◉◯◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 10, 23, 46, 55]
StringLegalActions() = ["e1", "c2", "h3", "g6", "h7"]

# Apply action "h3"
action: 23

# State 49
# White (o) to play:
#   a b c d e f g h
# 1 x o o o - - - - 1
# 2 x o - - x x x - 2
# 3 x o o x x x x x 3
# 4 o o x x x x - x 4
# 5 o o x x x x x x 5
# 6 x x o x x o - - 6
# 7 x o o o o o o - 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63, 20, 31, 39, 24, 23]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - x x x - 2\n3 x o o x x x x x 3\n4 o o x x x x - x 4\n5 o o x x x x x x 5\n6 x x o x x o - - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - - x x x - 2\n3 x o o x x x x x 3\n4 o o x x x x - x 4\n5 o o x x x x x x 5\n6 x x o x x o - - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◉◉◯◯◯◉  ◉◯◯◯◉◉◉◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◉◯◯◉◉◉◉◉  ◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◉◯  ◯◯◉◉◉◉◯◉  ◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◯◉◉◉◉◉◉  ◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◯◯◯◉  ◯◉◯◯◯◯◯◯  ◉◯◯◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◯◉◉◯◯◯◯◯  ◉◯◯◉◉◉◉◉
◯◯◯◯◯◯◉◯  ◉◉◯◯◯◯◯◯  ◯◯◉◉◉◉◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯  ◯◯◉◉◉◉◉◉
◯◯◯◯◯◯◉◉  ◯◯◉◯◯◉◯◯  ◉◉◯◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 5, 7, 11, 15, 30]
StringLegalActions() = ["e1", "f1", "h1", "d2", "h2", "g4"]

# Apply action "d2"
action: 11

# State 50
# Black (x) to play:
#   a b c d e f g h
# 1 x o o o - - - - 1
# 2 x o - o x x x - 2
# 3 x o o o x x x x 3
# 4 o o x o x x - x 4
# 5 o o x o x x x x 5
# 6 x x o o x o - - 6
# 7 x o o o o o o - 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63, 20, 31, 39, 24, 23, 11]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - o x x x - 2\n3 x o o o x x x x 3\n4 o o x o x x - x 4\n5 o o x o x x x x 5\n6 x x o o x o - - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - o x x x - 2\n3 x o o o x x x x 3\n4 o o x o x x - x 4\n5 o o x o x x x x 5\n6 x x o o x o - - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◉◯◯◯◯◉  ◉◯◯◯◉◉◉◯  ◯◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◉◯  ◯◯◉◯◉◉◯◉  ◉◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◉◉◉◉  ◉◉◯◉◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◯◯◉◯◯◯  ◯◯◉◉◯◉◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◯◯◯◯◉  ◯◉◯◉◯◯◯◯  ◉◯◯◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯  ◉◯◯◯◉◉◉◉
◯◯◯◯◯◯◉◯  ◉◉◯◉◯◯◯◯  ◯◯◉◯◉◉◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◯◯◯◯  ◯◯◉◯◉◉◉◉
◯◯◯◯◯◯◉◉  ◯◯◉◉◯◉◯◯  ◉◉◯◯◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 10, 46, 55]
StringLegalActions() = ["e1", "c2", "g6", "h7"]

# Apply action "g6"
action: 46

# State 51
# White (o) to play:
#   a b c d e f g h
# 1 x o o o - - - - 1
# 2 x o - o x x x - 2
# 3 x o o o x x x x 3
# 4 o o x o x x - x 4
# 5 o o x o x x x x 5
# 6 x x o o x x x - 6
# 7 x o o o o o o - 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63, 20, 31, 39, 24, 23, 11, 46]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - o x x x - 2\n3 x o o o x x x x 3\n4 o o x o x x - x 4\n5 o o x o x x x x 5\n6 x x o o x x x - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - o x x x - 2\n3 x o o o x x x x 3\n4 o o x o x x - x 4\n5 o o x o x x x x 5\n6 x x o o x x x - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◉◯◯◯◯◉  ◉◯◯◯◉◉◉◯  ◯◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◉◯  ◯◯◉◯◉◉◯◉  ◉◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◉◉◉◉  ◉◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◯◯◉◉◉◯  ◯◯◉◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◯◯◯◯◉  ◯◉◯◉◯◯◯◯  ◉◯◯◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯  ◉◯◯◯◉◉◉◉
◯◯◯◯◯◯◉◯  ◉◉◯◉◯◯◯◯  ◯◯◉◯◉◉◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◯◯◯◯  ◯◯◉◯◉◉◉◉
◯◯◯◯◯◯◯◉  ◯◯◉◉◯◯◯◯  ◉◉◯◯◉◉◉◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 5, 6, 7, 15, 30, 47, 55]
StringLegalActions() = ["e1", "f1", "g1", "h1", "h2", "g4", "h6", "h7"]

# Apply action "g4"
action: 30

# State 52
# Black (x) to play:
#   a b c d e f g h
# 1 x o o o - - - - 1
# 2 x o - o o x x - 2
# 3 x o o o x o x x 3
# 4 o o x o o o o x 4
# 5 o o x o x o o x 5
# 6 x x o o o x o - 6
# 7 x o o o o o o - 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63, 20, 31, 39, 24, 23, 11, 46, 30]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - o o x x - 2\n3 x o o o x o x x 3\n4 o o x o o o o x 4\n5 o o x o x o o x 5\n6 x x o o o x o - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x o - o o x x - 2\n3 x o o o x o x x 3\n4 o o x o o o o x 4\n5 o o x o x o o x 5\n6 x x o o o x o - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◉◯◯◯◯◉  ◉◯◯◯◯◉◉◯  ◯◉◯◉◉◯◯◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◉◯◉◉  ◯◉◉◉◯◉◯◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◉  ◉◉◯◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◉◯◯◉  ◉◉◯◉◯◉◉◯
◯◯◯◯◯◯◯◉  ◉◉◯◯◯◉◯◯  ◯◯◉◉◉◯◉◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◯◯◯◯◉  ◯◉◯◉◉◯◯◯  ◉◯◯◯◯◉◉◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◯◉◯◯  ◉◯◯◯◉◯◉◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◯  ◯◯◉◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉◯  ◯◯◉◯◉◯◯◉
◯◯◯◯◯◯◯◉  ◯◯◉◉◉◯◉◯  ◉◉◯◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 5, 10, 47, 55]
StringLegalActions() = ["e1", "f1", "c2", "h6", "h7"]

# Apply action "c2"
action: 10

# State 53
# White (o) to play:
#   a b c d e f g h
# 1 x o o o - - - - 1
# 2 x x x x x x x - 2
# 3 x o x o x o x x 3
# 4 o o x o o o o x 4
# 5 o o x o x o o x 5
# 6 x x o o o x o - 6
# 7 x o o o o o o - 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63, 20, 31, 39, 24, 23, 11, 46, 30, 10]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x x x x x x x - 2\n3 x o x o x o x x 3\n4 o o x o o o o x 4\n5 o o x o x o o x 5\n6 x x o o o x o - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x x x x x x x - 2\n3 x o x o x o x x 3\n4 o o x o o o o x 4\n5 o o x o x o o x 5\n6 x x o o o x o - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◉  ◯◉◯◉◯◉◯◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◉  ◉◉◯◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◉◯◯◉  ◉◉◯◉◯◉◉◯
◯◯◯◯◯◯◯◉  ◉◉◯◯◯◉◯◯  ◯◯◉◉◉◯◉◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◯  ◉◯◉◯◉◯◉◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◯  ◯◯◉◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉◯  ◯◯◉◯◉◯◯◉
◯◯◯◯◯◯◯◉  ◯◯◉◉◉◯◉◯  ◉◉◯◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 5, 6, 7, 15]
StringLegalActions() = ["e1", "f1", "g1", "h1", "h2"]

# Apply action "h2"
action: 15

# State 54
# Black (x) to play:
#   a b c d e f g h
# 1 x o o o - - - - 1
# 2 x x x x x x x o 2
# 3 x o x o x o o x 3
# 4 o o x o o o o x 4
# 5 o o x o x o o x 5
# 6 x x o o o x o - 6
# 7 x o o o o o o - 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63, 20, 31, 39, 24, 23, 11, 46, 30, 10, 15]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x x x x x x x o 2\n3 x o x o x o o x 3\n4 o o x o o o o x 4\n5 o o x o x o o x 5\n6 x x o o o x o - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x x x x x x x o 2\n3 x o x o x o o x 3\n4 o o x o o o o x 4\n5 o o x o x o o x 5\n6 x x o o o x o - 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◉  ◯◉◯◉◯◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◉  ◉◉◯◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◉◯◯◉  ◉◉◯◉◯◉◉◯
◯◯◯◯◯◯◯◉  ◉◉◯◯◯◉◯◯  ◯◯◉◉◉◯◉◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◉◯  ◉◯◉◯◉◯◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◯  ◯◯◉◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉◯  ◯◯◉◯◉◯◯◉
◯◯◯◯◯◯◯◉  ◯◯◉◉◉◯◉◯  ◉◉◯◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 7, 47, 55]
StringLegalActions() = ["e1", "h1", "h6", "h7"]

# Apply action "h6"
action: 47

# State 55
# White (o) to play:
#   a b c d e f g h
# 1 x o o o - - - - 1
# 2 x x x x x x x o 2
# 3 x o x o x o o x 3
# 4 o o x o o x o x 4
# 5 o o x o x o x x 5
# 6 x x o o o x x x 6
# 7 x o o o o o o - 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63, 20, 31, 39, 24, 23, 11, 46, 30, 10, 15, 47]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x x x x x x x o 2\n3 x o x o x o o x 3\n4 o o x o o x o x 4\n5 o o x o x o x x 5\n6 x x o o o x x x 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - - - - 1\n2 x x x x x x x o 2\n3 x o x o x o o x 3\n4 o o x o o x o x 4\n5 o o x o x o x x 5\n6 x x o o o x x x 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◉  ◯◉◯◉◯◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◉◯◉  ◉◉◯◉◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◉◯◉◉  ◉◉◯◉◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◉◯  ◉◯◉◯◉◯◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◯◉◯  ◯◯◉◯◯◉◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◯◉◯◯  ◯◯◉◯◉◯◉◉
◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯  ◉◉◯◯◯◉◉◉
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 5, 6, 7, 55]
StringLegalActions() = ["e1", "f1", "g1", "h1", "h7"]

# Apply action "f1"
action: 5

# State 56
# Black (x) to play:
#   a b c d e f g h
# 1 x o o o - o - - 1
# 2 x x x x o o x o 2
# 3 x o x o x o o x 3
# 4 o o x o o x o x 4
# 5 o o x o x o x x 5
# 6 x x o o o x x x 6
# 7 x o o o o o o - 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63, 20, 31, 39, 24, 23, 11, 46, 30, 10, 15, 47, 5]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47 5"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47 5"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - o - - 1\n2 x x x x o o x o 2\n3 x o x o x o o x 3\n4 o o x o o x o x 4\n5 o o x o x o x x 5\n6 x x o o o x x x 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o - o - - 1\n2 x x x x o o x o 2\n3 x o x o x o o x 3\n4 o o x o o x o x 4\n5 o o x o x o x x 5\n6 x x o o o x x x 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◉
◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◉  ◯◉◯◉◯◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◉◯◉  ◉◉◯◉◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◉◯◉◉  ◉◉◯◉◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◉◯◉◉  ◯◉◉◉◯◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◉◉◯◉  ◉◉◉◉◯◯◉◯
◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◉◯  ◉◯◉◯◉◯◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◯◉◯  ◯◯◉◯◯◉◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◯◉◯◯  ◯◯◉◯◉◯◉◉
◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯  ◉◉◯◯◯◉◉◉
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 6, 7, 55]
StringLegalActions() = ["e1", "g1", "h1", "h7"]

# Apply action "g1"
action: 6

# State 57
# White (o) to play:
#   a b c d e f g h
# 1 x o o o - o x - 1
# 2 x x x x o x x o 2
# 3 x o x o x o o x 3
# 4 o o x o o x o x 4
# 5 o o x o x o x x 5
# 6 x x o o o x x x 6
# 7 x o o o o o o - 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63, 20, 31, 39, 24, 23, 11, 46, 30, 10, 15, 47, 5, 6]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47 5 6"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47 5 6"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47 5 6"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - o x - 1\n2 x x x x o x x o 2\n3 x o x o x o o x 3\n4 o o x o o x o x 4\n5 o o x o x o x x 5\n6 x x o o o x x x 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o - o x - 1\n2 x x x x o x x o 2\n3 x o x o x o o x 3\n4 o o x o o x o x 4\n5 o o x o x o x x 5\n6 x x o o o x x x 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◉◯◯◉  ◉◯◯◯◯◯◉◯  ◯◉◉◉◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◯◉◉◯  ◯◯◯◯◉◯◯◉
◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◉  ◯◉◯◉◯◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◉◯◉  ◉◉◯◉◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◉◯◉◉  ◉◉◯◉◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◉◯◯◉  ◯◉◉◉◯◉◯◯  ◉◯◯◯◯◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◉  ◉◉◉◉◯◉◉◯
◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◉◯  ◉◯◉◯◉◯◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◯◉◯  ◯◯◉◯◯◉◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◯◉◯◯  ◯◯◉◯◉◯◉◉
◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯  ◉◉◯◯◯◉◉◉
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 7, 55]
StringLegalActions() = ["e1", "h1", "h7"]

# Apply action "e1"
action: 4

# State 58
# Black (x) to play:
#   a b c d e f g h
# 1 x o o o o o x - 1
# 2 x x x o o o x o 2
# 3 x o o o x o o x 3
# 4 o o x o o x o x 4
# 5 o o x o x o x x 5
# 6 x x o o o x x x 6
# 7 x o o o o o o - 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63, 20, 31, 39, 24, 23, 11, 46, 30, 10, 15, 47, 5, 6, 4]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47 5 6 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47 5 6 4"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47 5 6 4"
ObservationString(0) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o o o x - 1\n2 x x x o o o x o 2\n3 x o o o x o o x 3\n4 o o x o o x o x 4\n5 o o x o x o x x 5\n6 x x o o o x x x 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "Black (x) to play:\n  a b c d e f g h  \n1 x o o o o o x - 1\n2 x x x o o o x o 2\n3 x o o o x o o x 3\n4 o o x o o x o x 4\n5 o o x o x o x x 5\n6 x x o o o x x x 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◉◯  ◯◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◉◯  ◯◯◯◉◉◉◯◉
◯◯◯◯◯◯◯◯  ◉◯◯◯◉◯◯◉  ◯◉◉◉◯◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◉◯◉  ◉◉◯◉◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◉◯◉◉  ◉◉◯◉◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◯◯  ◉◯◯◯◯◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◯◉  ◉◉◉◯◯◯◉◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◯◉◉◯  ◉◯◯◯◉◯◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◯◉◯  ◯◯◉◯◯◉◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◯◉◯◯  ◯◯◉◯◉◯◉◉
◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯  ◉◉◯◯◯◉◉◉
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [7, 55]
StringLegalActions() = ["h1", "h7"]

# Apply action "h1"
action: 7

# State 59
# White (o) to play:
#   a b c d e f g h
# 1 x o o o o o x x 1
# 2 x x x o o o x x 2
# 3 x o o o x o o x 3
# 4 o o x o o x o x 4
# 5 o o x o x o x x 5
# 6 x x o o o x x x 6
# 7 x o o o o o o - 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63, 20, 31, 39, 24, 23, 11, 46, 30, 10, 15, 47, 5, 6, 4, 7]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47 5 6 4 7"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47 5 6 4 7"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47 5 6 4 7"
ObservationString(0) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o o o x x 1\n2 x x x o o o x x 2\n3 x o o o x o o x 3\n4 o o x o o x o x 4\n5 o o x o x o x x 5\n6 x x o o o x x x 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "White (o) to play:\n  a b c d e f g h  \n1 x o o o o o x x 1\n2 x x x o o o x x 2\n3 x o o o x o o x 3\n4 o o x o o x o x 4\n5 o o x o x o x x 5\n6 x x o o o x x x 6\n7 x o o o o o o - 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◉◉  ◯◯◯◉◉◉◯◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◉◯◯◉  ◯◉◉◉◯◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◉◯◉  ◉◉◯◉◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◉◯◉◉  ◉◉◯◉◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯  ◉◯◯◯◯◯◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◯◯  ◉◉◉◯◯◯◉◉
◯◯◯◯◯◯◯◯  ◯◉◉◉◯◉◉◯  ◉◯◯◯◉◯◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◯◉◯  ◯◯◉◯◯◉◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◯◉◯◯  ◯◯◉◯◉◯◉◉
◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯  ◉◉◯◯◯◉◉◉
◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [55]
StringLegalActions() = ["h7"]

# Apply action "h7"
action: 55

# State 60
# Terminal State:
#   a b c d e f g h
# 1 x o o o o o x x 1
# 2 x x x o o o x x 2
# 3 x o o o x o o x 3
# 4 o o x o o x o x 4
# 5 o o x o x o x x 5
# 6 x x o o o x o x 6
# 7 x o o o o o o o 7
# 8 x o o o o o o o 8
#   a b c d e f g h
IsTerminal() = True
History() = [44, 43, 26, 29, 45, 25, 17, 52, 21, 13, 37, 42, 41, 53, 34, 8, 16, 50, 0, 48, 61, 60, 59, 33, 18, 51, 58, 9, 2, 49, 62, 1, 40, 54, 56, 32, 22, 57, 38, 3, 14, 19, 12, 63, 20, 31, 39, 24, 23, 11, 46, 30, 10, 15, 47, 5, 6, 4, 7, 55]
HistoryString() = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47 5 6 4 7 55"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47 5 6 4 7 55"
InformationStateString(1) = "44 43 26 29 45 25 17 52 21 13 37 42 41 53 34 8 16 50 0 48 61 60 59 33 18 51 58 9 2 49 62 1 40 54 56 32 22 57 38 3 14 19 12 63 20 31 39 24 23 11 46 30 10 15 47 5 6 4 7 55"
ObservationString(0) = "Terminal State:\n  a b c d e f g h  \n1 x o o o o o x x 1\n2 x x x o o o x x 2\n3 x o o o x o o x 3\n4 o o x o o x o x 4\n5 o o x o x o x x 5\n6 x x o o o x o x 6\n7 x o o o o o o o 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationString(1) = "Terminal State:\n  a b c d e f g h  \n1 x o o o o o x x 1\n2 x x x o o o x x 2\n3 x o o o x o o x 3\n4 o o x o o x o x 4\n5 o o x o x o x x 5\n6 x x o o o x o x 6\n7 x o o o o o o o 7\n8 x o o o o o o o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◉◉  ◯◯◯◉◉◉◯◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◉◯◯◉  ◯◉◉◉◯◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◉◯◉  ◉◉◯◉◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◉◯◉◉  ◉◉◯◉◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◯◯◯◉◯◉  ◯◯◉◉◉◯◉◯
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯  ◉◯◯◯◯◯◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◯◯  ◉◉◉◯◯◯◉◉
◯◯◯◯◯◯◯◯  ◯◉◉◉◯◉◉◯  ◉◯◯◯◉◯◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◯◉◯  ◯◯◉◯◯◉◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◯◉◯◯  ◯◯◉◯◉◯◉◉
◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◉◯  ◉◉◯◯◯◉◯◉
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
Rewards() = [-1.0, 1.0]
Returns() = [-1.0, 1.0]
